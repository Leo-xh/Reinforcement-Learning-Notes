{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planning and Learning\n",
    "\n",
    "#### Models\n",
    "+ distribution models: describes of all possibilities and their probabilities.\n",
    "+ sample models: produce just one of the possibilities sampled according to the probabilities.\n",
    "\n",
    "#### Planning\n",
    "+ state space planning\n",
    "+ plan space planning(hard to apply)\n",
    "\n",
    "##### Space planning\n",
    "$$\n",
    "    model \\xrightarrow[]{} simulated\\;experience \\xrightarrow[]{backups} values \\xrightarrow[]{} policy\n",
    "$$\n",
    "\n",
    "\n",
    "#### Dyna\n",
    "\n",
    "<img src=\"./img/Dyna.png\" style=\"zoom:60%\" />\n",
    "\n",
    "#### Dyna-Q\n",
    "\n",
    "<img src=\"./img/Dyna-Q.png\" style=\"zoom:60%\" />\n",
    "\n",
    "#### When the Model Is Wrong\n",
    "\n",
    "Introducing heuristic to encourage exploration and meanwhile exploit by selecting the optimal policy.\n",
    "\n",
    "#### Prioritized Sweeping\n",
    "\n",
    "use the magnitudes of the changes as the priority of the states. The proceedings of the nodes are updated later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected vs. Sample Updates\n",
    "\n",
    "Three dimensions of one-step value updates:\n",
    "1. whether they update the state values or action values.\n",
    "2. whether they estimate the value for the optimal policy or an arbitrary given policy.\n",
    "3. expected updates or sample updates.\n",
    "\n",
    "<img src=\"./img/3-dimension.png\" style=\"zoom:70%\" />\n",
    "\n",
    "|Comparison|Expected|Sample|\n",
    "|:-|:-|:-|\n",
    "|Distribution Model|Yes|No|\n",
    "|Sampling Error|No|Yes|\n",
    "|Computation|More|Less|\n",
    "\n",
    "#### Trajectory Sampling\n",
    "\n",
    "Two ways of distribution updates:\n",
    "\n",
    "+ Exhaustive sweeps\n",
    "+ Trajectory sampling\n",
    "\n",
    "#### Decision Time Planning\n",
    "\n",
    "Use the experience to select an action for the current state.\n",
    "\n",
    "#### Rollout Algorithm\n",
    "\n",
    "ake average of many trajectories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MCTS\n",
    "\n",
    "1. Selection\n",
    "2. Expansion\n",
    "3. Simulation\n",
    "4. Backup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
